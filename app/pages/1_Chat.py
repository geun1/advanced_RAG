import os
import sys
from pathlib import Path
import streamlit as st

BASE_DIR = Path(__file__).resolve().parents[2]
if str(BASE_DIR) not in sys.path:
    sys.path.append(str(BASE_DIR))

from src.config import settings
from src.modules.chunking import DefaultTextSplitter
from src.modules.embeddings import OpenAIEmbeddings
from src.modules.vectorstore import ChromaVectorStore, ElasticVectorStore, CompositeVectorStore
from src.modules.retriever import SimpleRetriever, HybridRetriever
from src.modules.llm import OpenAIChatLLM
from src.modules.pipeline import RAGPipeline
from src.modules.tracing import TraceRecorder

st.set_page_config(page_title="RAG Chat", page_icon="ğŸ’¬", layout="wide")

st.title("ğŸ’¬ RAG Chat")
if not settings.openai_api_key:
    st.warning(".envì˜ OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")

@st.cache_resource(show_spinner=False)
def get_pipeline() -> RAGPipeline:
    splitter = DefaultTextSplitter()
    embeddings = OpenAIEmbeddings()
    dense = ChromaVectorStore(embeddings=embeddings)
    sparse = ElasticVectorStore()
    store = CompositeVectorStore([dense, sparse])
    # ES ë¯¸ì‚¬ìš©/ë¯¸ê°€ìš© ì‹œ HybridRetrieverê°€ ìë™ í´ë°±
    retriever = HybridRetriever(dense_store=dense, sparse_store=sparse)
    llm = OpenAIChatLLM()
    return RAGPipeline(splitter, embeddings, store, retriever, llm)


with st.sidebar:
    top_k = st.slider("Top-K", min_value=1, max_value=10, value=settings.top_k)
    max_tokens = st.slider("Max Tokens", min_value=128, max_value=2048, value=settings.max_tokens, step=64)
    st.markdown("---")
    enable_rerank = st.toggle("Rerank í™œì„±í™”", value=settings.rerank_enabled)
    rerank_top_n = st.slider("Rerank Top-N", min_value=1, max_value=10, value=min(settings.rerank_top_n, settings.top_k))

pipeline = get_pipeline()

query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if st.button("ì§ˆì˜") and query.strip():
    trace = TraceRecorder()
    with st.spinner("ê²€ìƒ‰ ë° ìƒì„± ì¤‘..."):
        # ë™ì  ì„¤ì • ë°˜ì˜ (ì„¸ì…˜ ë™ì•ˆ)
        from src.config import settings as _s
        _s.rerank_enabled = bool(enable_rerank)
        _s.rerank_top_n = int(min(rerank_top_n, top_k))
        result = pipeline.answer(query, k=top_k, trace=trace, max_tokens=max_tokens)

    st.subheader("ì‘ë‹µ")
    st.write(result["answer"])  # type: ignore

    st.subheader("ì°¸ì¡° ë¬¸ì„œ")
    for i, meta in enumerate(result["sources"]):  # type: ignore
        src = meta.get('source', 'unknown')
        law_path = meta.get('law_path')
        if law_path:
            st.markdown(f"- ì†ŒìŠ¤ {i+1}: `{src}` Â· ë²•ë ¹ ìœ„ì¹˜: {law_path}")
        else:
            st.markdown(f"- ì†ŒìŠ¤ {i+1}: `{src}`")

    # ë‹¨ê³„ íŠ¸ë ˆì´ìŠ¤
    with st.expander("ë‹¨ê³„ íŠ¸ë ˆì´ìŠ¤ ë³´ê¸°"):
        events = result["trace"]  # type: ignore
        for e in events:
            st.json(e)


